{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranav-85/cricket_chatbot/blob/main/finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqi-6WC2fkiY"
      },
      "source": [
        "# Finetuning Mistral-7B on cricket data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M3Krx7Hfkia"
      },
      "source": [
        "## 1. Data Cleaning and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSqdbvysfkia",
        "outputId": "5b52bf62-5413-4fd4-a3ee-7013111adb03"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start as the Python Environment 'myenv (Python -1.-1.-1)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
          ]
        }
      ],
      "source": [
        "import re\n",
        "import json\n",
        "import os\n",
        "import PyPDF2\n",
        "# !pip install PyMuPDF\n",
        "# !pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfbHgxPlfkib"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text from a PDF file.\"\"\"\n",
        "    try:\n",
        "        with open(pdf_path, \"rb\") as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
        "        return text if text.strip() else None  # Ensure non-empty text\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from {pdf_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Remove unnecessary spaces, line breaks, and special characters.\"\"\"\n",
        "    text = re.sub(r\"\\s+\", \" \", text)  # Normalize whitespace\n",
        "    text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)  # Remove non-ASCII characters\n",
        "    return text.strip()\n",
        "\n",
        "def chunk_text(text, chunk_size=1024):\n",
        "    \"\"\"Split text into smaller chunks of specified size.\"\"\"\n",
        "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "def categorize_file(filename, directory):\n",
        "    \"\"\"Determine file category based on directory and filename.\"\"\"\n",
        "    filename_lower = filename.lower()\n",
        "\n",
        "    if directory.endswith(\"icc\"):\n",
        "        if re.search(r\"rules|playing-conditions\", filename_lower):\n",
        "            return \"cricket_rules\"\n",
        "        elif re.search(r\"report|financial|annual\", filename_lower):\n",
        "            return \"annual_reports\"\n",
        "        elif re.search(r\"media|press|guide\", filename_lower):\n",
        "            return \"media_guide\"\n",
        "    elif directory.endswith(\"mcc_rules\"):\n",
        "        return \"mcc_rules\"\n",
        "\n",
        "    return \"general\"\n",
        "\n",
        "def apply_template(category, text, filename):\n",
        "    \"\"\"Apply prompt template based on category.\"\"\"\n",
        "    templates = {\n",
        "        \"cricket_rules\": {\n",
        "            \"instruction\": f\"Explain the following ICC rule in cricket.\",\n",
        "            \"input\": text,\n",
        "            \"output\": \"\"\n",
        "        },\n",
        "        \"mcc_rules\": {\n",
        "            \"instruction\": f\"Summarize the MCC rule for {filename.replace('.txt', '').replace('mcc_', '').replace('_', ' ')}.\",\n",
        "            \"input\": text,\n",
        "            \"output\": \"\"\n",
        "        },\n",
        "        \"annual_reports\": {\n",
        "            \"instruction\": \"Summarize the ICC Annual Report.\",\n",
        "            \"input\": text,\n",
        "            \"output\": \"\"\n",
        "        },\n",
        "        \"media_guide\": {\n",
        "            \"instruction\": \"Extract key details from the ICC Media Guide.\",\n",
        "            \"input\": text,\n",
        "            \"output\": \"\"\n",
        "        },\n",
        "        \"general\": {\n",
        "            \"instruction\": \"Provide information on the following document.\",\n",
        "            \"input\": text,\n",
        "            \"output\": \"\"\n",
        "        }\n",
        "    }\n",
        "    return templates.get(category, templates[\"general\"])\n",
        "\n",
        "def prepare_finetuning_dataset(root_dir, output_file):\n",
        "    \"\"\"Prepares a fine-tuning dataset by reading text from ICC PDFs and MCC rule text files.\"\"\"\n",
        "\n",
        "    dataset = []\n",
        "    directories = [\"icc\", \"mcc_rules\"]  # Subdirectories inside 'data' folder\n",
        "\n",
        "    for subdir in directories:\n",
        "        dir_path = os.path.join(root_dir, subdir)\n",
        "\n",
        "        # Step 1: Verify directory exists\n",
        "        if not os.path.exists(dir_path):\n",
        "            print(f\"Warning: Directory '{dir_path}' does not exist. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Step 2: List files in directory\n",
        "        files = os.listdir(dir_path)\n",
        "        if not files:\n",
        "            print(f\"Warning: No files found in '{dir_path}'. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nFound {len(files)} files in '{dir_path}':\")\n",
        "        for file in files:\n",
        "            print(f\"  - {file}\")\n",
        "\n",
        "        # Step 3: Process each file\n",
        "        for filename in files:\n",
        "            file_path = os.path.join(dir_path, filename)\n",
        "\n",
        "            try:\n",
        "                content = None\n",
        "\n",
        "                if filename.endswith(\".txt\"):\n",
        "                    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "                        content = file.read()\n",
        "                elif filename.endswith(\".pdf\"):\n",
        "                    content = extract_text_from_pdf(file_path)\n",
        "\n",
        "                if not content:\n",
        "                    print(f\"Skipping empty file: {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Clean and chunk text\n",
        "                cleaned_text = clean_text(content)\n",
        "                chunks = chunk_text(cleaned_text)\n",
        "\n",
        "                # Categorize and apply prompt template to each chunk\n",
        "                category = categorize_file(filename, subdir)\n",
        "\n",
        "                for chunk in chunks:\n",
        "                    template = apply_template(category, chunk, filename)\n",
        "                    dataset.append({\n",
        "                        \"filename\": filename,\n",
        "                        \"category\": category,\n",
        "                        \"instruction\": template[\"instruction\"],\n",
        "                        \"input\": template[\"input\"],\n",
        "                        \"output\": template[\"output\"]\n",
        "                    })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing '{filename}': {e}\")\n",
        "\n",
        "    # Step 4: Save dataset to JSON file\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as json_file:\n",
        "        json.dump(dataset, json_file, indent=4)\n",
        "\n",
        "    print(\"\\nDataset preparation completed. Output saved as:\", output_file)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w0TYatDfkic",
        "outputId": "df7fdf82-4699-4939-be55-df87ac43fe4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Found 126 files in 'c:\\Users\\msaip\\Projects\\python_chatbot\\data\\icc':\n",
            "  - annual-report_1.pdf\n",
            "  - annual-report_10.pdf\n",
            "  - annual-report_11.pdf\n",
            "  - annual-report_12.pdf\n",
            "  - annual-report_13.pdf\n",
            "  - annual-report_14.pdf\n",
            "  - annual-report_15.pdf\n",
            "  - annual-report_16.pdf\n",
            "  - annual-report_17.pdf\n",
            "  - annual-report_18.pdf\n",
            "  - annual-report_19.pdf\n",
            "  - annual-report_2.pdf\n",
            "  - annual-report_20.pdf\n",
            "  - annual-report_21.pdf\n",
            "  - annual-report_22.pdf\n",
            "  - annual-report_23.pdf\n",
            "  - annual-report_24.pdf\n",
            "  - annual-report_25.pdf\n",
            "  - annual-report_26.pdf\n",
            "  - annual-report_27.pdf\n",
            "  - annual-report_28.pdf\n",
            "  - annual-report_29.pdf\n",
            "  - annual-report_3.pdf\n",
            "  - annual-report_30.pdf\n",
            "  - annual-report_31.pdf\n",
            "  - annual-report_32.pdf\n",
            "  - annual-report_33.pdf\n",
            "  - annual-report_4.pdf\n",
            "  - annual-report_5.pdf\n",
            "  - annual-report_6.pdf\n",
            "  - annual-report_7.pdf\n",
            "  - annual-report_8.pdf\n",
            "  - annual-report_9.pdf\n",
            "  - code-of-conduct_1.pdf\n",
            "  - code-of-conduct_2.pdf\n",
            "  - decision-review-system_1.pdf\n",
            "  - decision-review-system_2.pdf\n",
            "  - duckworth-lewis-stern_1.pdf\n",
            "  - duckworth-lewis-stern_2.pdf\n",
            "  - illegal-bowling-actions_1.pdf\n",
            "  - illegal-bowling-actions_2.pdf\n",
            "  - media-guide_1.pdf\n",
            "  - media-guide_10.pdf\n",
            "  - media-guide_11.pdf\n",
            "  - media-guide_12.pdf\n",
            "  - media-guide_13.pdf\n",
            "  - media-guide_14.pdf\n",
            "  - media-guide_15.pdf\n",
            "  - media-guide_16.pdf\n",
            "  - media-guide_17.pdf\n",
            "  - media-guide_18.pdf\n",
            "  - media-guide_19.pdf\n",
            "  - media-guide_2.pdf\n",
            "  - media-guide_3.pdf\n",
            "  - media-guide_4.pdf\n",
            "  - media-guide_5.pdf\n",
            "  - media-guide_6.pdf\n",
            "  - media-guide_7.pdf\n",
            "  - media-guide_8.pdf\n",
            "  - media-guide_9.pdf\n",
            "  - playing-conditions_1.pdf\n",
            "  - playing-conditions_10.pdf\n",
            "  - playing-conditions_11.pdf\n",
            "  - playing-conditions_12.pdf\n",
            "  - playing-conditions_13.pdf\n",
            "  - playing-conditions_14.pdf\n",
            "  - playing-conditions_15.pdf\n",
            "  - playing-conditions_16.pdf\n",
            "  - playing-conditions_17.pdf\n",
            "  - playing-conditions_19.pdf\n",
            "  - playing-conditions_2.pdf\n",
            "  - playing-conditions_20.pdf\n",
            "  - playing-conditions_21.pdf\n",
            "  - playing-conditions_22.pdf\n",
            "  - playing-conditions_23.pdf\n",
            "  - playing-conditions_24.pdf\n",
            "  - playing-conditions_25.pdf\n",
            "  - playing-conditions_26.pdf\n",
            "  - playing-conditions_27.pdf\n",
            "  - playing-conditions_28.pdf\n",
            "  - playing-conditions_29.pdf\n",
            "  - playing-conditions_3.pdf\n",
            "  - playing-conditions_30.pdf\n",
            "  - playing-conditions_31.pdf\n",
            "  - playing-conditions_32.pdf\n",
            "  - playing-conditions_33.pdf\n",
            "  - playing-conditions_34.pdf\n",
            "  - playing-conditions_35.pdf\n",
            "  - playing-conditions_36.pdf\n",
            "  - playing-conditions_37.pdf\n",
            "  - playing-conditions_38.pdf\n",
            "  - playing-conditions_39.pdf\n",
            "  - playing-conditions_4.pdf\n",
            "  - playing-conditions_40.pdf\n",
            "  - playing-conditions_41.pdf\n",
            "  - playing-conditions_42.pdf\n",
            "  - playing-conditions_43.pdf\n",
            "  - playing-conditions_44.pdf\n",
            "  - playing-conditions_45.pdf\n",
            "  - playing-conditions_46.pdf\n",
            "  - playing-conditions_47.pdf\n",
            "  - playing-conditions_48.pdf\n",
            "  - playing-conditions_49.pdf\n",
            "  - playing-conditions_5.pdf\n",
            "  - playing-conditions_50.pdf\n",
            "  - playing-conditions_51.pdf\n",
            "  - playing-conditions_52.pdf\n",
            "  - playing-conditions_53.pdf\n",
            "  - playing-conditions_54.pdf\n",
            "  - playing-conditions_55.pdf\n",
            "  - playing-conditions_6.pdf\n",
            "  - playing-conditions_7.pdf\n",
            "  - playing-conditions_8.pdf\n",
            "  - playing-conditions_9.pdf\n",
            "  - playing-handbook_1.pdf\n",
            "  - playing-handbook_10.pdf\n",
            "  - playing-handbook_11.pdf\n",
            "  - playing-handbook_12.pdf\n",
            "  - playing-handbook_2.pdf\n",
            "  - playing-handbook_3.pdf\n",
            "  - playing-handbook_4.pdf\n",
            "  - playing-handbook_5.pdf\n",
            "  - playing-handbook_6.pdf\n",
            "  - playing-handbook_7.pdf\n",
            "  - playing-handbook_8.pdf\n",
            "  - playing-handbook_9.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "incorrect startxref pointer(1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error extracting text from c:\\Users\\msaip\\Projects\\python_chatbot\\data\\icc\\playing-handbook_12.pdf: EOF marker not found\n",
            "Skipping empty file: playing-handbook_12.pdf\n",
            "\n",
            "Found 44 files in 'c:\\Users\\msaip\\Projects\\python_chatbot\\data\\mcc_rules':\n",
            "  - appeals.txt\n",
            "  - batsman-out-of-his-her-ground.txt\n",
            "  - batsman-s-innings;-runners.txt\n",
            "  - boundaries.txt\n",
            "  - bowled.txt\n",
            "  - bye-and-leg-bye.txt\n",
            "  - caught.txt\n",
            "  - covering-the-pitch.txt\n",
            "  - dead-ball.txt\n",
            "  - declaration-and-forfeiture.txt\n",
            "  - fielders-absence;-substitutes.txt\n",
            "  - hit-the-ball-twice.txt\n",
            "  - hit-wicket.txt\n",
            "  - innings.txt\n",
            "  - intervals.txt\n",
            "  - law-appendices.txt\n",
            "  - leg-before-wicket.txt\n",
            "  - no-ball.txt\n",
            "  - obstructing-the-field.txt\n",
            "  - players-conduct.txt\n",
            "  - practice-on-the-field.txt\n",
            "  - preamble-to-the-laws-spirit-of-cricket.txt\n",
            "  - preparation-and-maintenance-of-the-playing-area.txt\n",
            "  - run-out.txt\n",
            "  - scoring-runs.txt\n",
            "  - start-of-play;-cessation-of-play.txt\n",
            "  - stumped.txt\n",
            "  - the-ball.txt\n",
            "  - the-bat.txt\n",
            "  - the-creases.txt\n",
            "  - the-fielder.txt\n",
            "  - the-follow-on.txt\n",
            "  - the-over.txt\n",
            "  - the-pitch.txt\n",
            "  - the-players.txt\n",
            "  - the-result.txt\n",
            "  - the-scorers.txt\n",
            "  - the-umpires.txt\n",
            "  - the-wicket-is-down.txt\n",
            "  - the-wicket-keeper.txt\n",
            "  - the-wickets.txt\n",
            "  - timed-out.txt\n",
            "  - unfair-play.txt\n",
            "  - wide-ball.txt\n",
            "\n",
            "Dataset preparation completed. Output saved as: finetune_dataset.json\n"
          ]
        }
      ],
      "source": [
        "PATH = 'c:\\\\Users\\\\msaip\\\\Projects\\\\python_chatbot\\\\data'\n",
        "prepare_finetuning_dataset(PATH, \"finetune_dataset.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32Hjrw_efkic"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26bqEk6Nfkic"
      },
      "source": [
        "## 2. Finetune mistral-7b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMdQk9UBfkic",
        "outputId": "1f02f8c9-658a-4b12-d485-8a186ccc271d"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.11.7)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/msaip/Projects/python_chatbot/.venv/bin/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers bitsandbytes trl peft sentencepiece wandb\n",
        "!pip install -q setuptools\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, BitsAndBytesConfig, HfArgumentParser, pipeline, logging\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSTpihy5fkid",
        "outputId": "96c2f90a-35ce-4557-abbb-961442722040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0y5-dC4fkid"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'mistralai/Mistral-7B-v0.1'\n",
        "DATASET_PATH = 'c:\\\\Users\\\\msaip\\\\Projects\\\\python_chatbot\\\\data\\\\finetune_dataset.json'\n",
        "FINETUNED_MODEL = 'mistral-7b-finetuned-cricket'\n",
        "\n",
        "#QLoRA parameters\n",
        "lora_r = 64\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "\n",
        "#bitsandbytes parameters\n",
        "use_4bit = True\n",
        "bnb_4bit_compute_type = 'float16'\n",
        "bnb_4bit_quant_type = 'nf4'\n",
        "use_nested_quant = False\n",
        "\n",
        "#TrainingArguments parameters\n",
        "output_dir = './results'\n",
        "num_train_epochs = 1\n",
        "fp16 = True\n",
        "bf16 = False\n",
        "per_device_train_batch_size = 1\n",
        "per_device_eval_batch_size = 1\n",
        "gradient_accumulation_steps = 1\n",
        "gradient_checkpointing = True\n",
        "max_grad_norm = 0.3\n",
        "learning_rate = 2e-4\n",
        "weight_decay = 0.001\n",
        "optim = \"paged_adamw_32bit\"\n",
        "lr_scheduler_type = \"cosine\"\n",
        "max_steps = -1\n",
        "warmup_ratio = 0.03\n",
        "group_by_length = True\n",
        "save_steps = 0\n",
        "logging_steps = 25\n",
        "\n",
        "#SFT parameters\n",
        "max_seq_length = None\n",
        "packing = False\n",
        "device_map = {\"\": 0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5UY1YsGfkid",
        "outputId": "2238d505-3594-4872-e4cb-cce7a5f6fbbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement torch (from versions: none)\n",
            "ERROR: No matching distribution found for torch\n"
          ]
        }
      ],
      "source": [
        "# !pip uninstall torch torchvision torchaudio -y\n",
        "# !python -m pip install --upgrade pip setuptools wheel\n",
        "!pip install --no-cache-dir torch torchvision --index-url https://download.pytorch.org/whl/cu121\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToRmeNw9fkid"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOF-eHvhfkie",
        "outputId": "76436d95-330a-4f0e-c3ef-63f3a05d9bb9"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Torch not compiled with CUDA enabled",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      4\u001b[39m bnb_config = BitsAndBytesConfig(\n\u001b[32m      5\u001b[39m     load_in_4bit=use_4bit,\n\u001b[32m      6\u001b[39m     bnb_4bit_quant_type=bnb_4bit_quant_type,\n\u001b[32m      7\u001b[39m     bnb_4bit_compute_type=compute_dtype,\n\u001b[32m      8\u001b[39m     bnb_4bit_use_double_quant=use_nested_quant,\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compute_dtype == torch.float16 \u001b[38;5;129;01mand\u001b[39;00m use_4bit:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m   major, _ = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_device_capability\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m major >= \u001b[32m8\u001b[39m:\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\msaip\\Projects\\python_chatbot\\myenv\\Lib\\site-packages\\torch\\cuda\\__init__.py:507\u001b[39m, in \u001b[36mget_device_capability\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_device_capability\u001b[39m(device: Optional[_device_t] = \u001b[38;5;28;01mNone\u001b[39;00m) -> Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m    495\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Get the cuda capability of a device.\u001b[39;00m\n\u001b[32m    496\u001b[39m \n\u001b[32m    497\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    505\u001b[39m \u001b[33;03m        tuple(int, int): the major and minor cuda capability of the device\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m     prop = \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m prop.major, prop.minor\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\msaip\\Projects\\python_chatbot\\myenv\\Lib\\site-packages\\torch\\cuda\\__init__.py:523\u001b[39m, in \u001b[36mget_device_properties\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_device_properties\u001b[39m(device: Optional[_device_t] = \u001b[38;5;28;01mNone\u001b[39;00m) -> _CudaDeviceProperties:\n\u001b[32m    512\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[32m    513\u001b[39m \n\u001b[32m    514\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    521\u001b[39m \u001b[33;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[32m    522\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[32m    524\u001b[39m     device = _get_device_index(device, optional=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    525\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m device < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device >= device_count():\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\msaip\\Projects\\python_chatbot\\myenv\\Lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    306\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    307\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    308\u001b[39m     )\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    313\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    314\u001b[39m     )\n",
            "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
          ]
        }
      ],
      "source": [
        "# dataset = json.load(open(DATASET_PATH, 'r'))\n",
        "compute_dtype = getattr(torch, bnb_4bit_compute_type)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=use_4bit,\n",
        "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_type=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=use_nested_quant,\n",
        ")\n",
        "\n",
        "if compute_dtype == torch.float16 and use_4bit:\n",
        "  major, _ = torch.cuda.get_device_capability()\n",
        "  if major >= 8:\n",
        "    print(\"=\"*80)\n",
        "    print(\"GPU supports. training with bf16=True\")\n",
        "    print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnLemfykfkie"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}